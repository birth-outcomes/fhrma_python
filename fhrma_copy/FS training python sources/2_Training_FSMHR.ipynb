{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 Training FSMHR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO00BeBaFp6Yk5mpQf424sp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utsb-fmm/FHRMA/blob/master/FS%20training%20python%20sources/2_Training_FSMHR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train FSMHR model\n",
        "\n",
        "Associated paper in https://www.preprints.org/manuscript/202207.0131/v1\n",
        "\n",
        "FHR Morphological Analysis Toolbox Copyright (C) 2022 Samuel Boudet, Faculté de Médecine et Maïeutique, samuel.boudet@gmail.com\n",
        "\n",
        "This file is part of FHR Morphological Analysis Toolbox\n",
        "\n",
        "FHR Morphological Analysis Toolbox is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
        "\n",
        "FHR Morphological Analysis Toolbox is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
        "\n",
        "You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/."
      ],
      "metadata": {
        "id": "KpURiGrkajuA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06_C9MNpSKYn"
      },
      "source": [
        "import tensorflow as tf\n",
        "import array\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import pickle\n",
        "from IPython.core.debugger import set_trace\n",
        "from tensorflow.keras import layers as lay\n",
        "from tensorflow.keras import regularizers\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUuxUFPXSV-4",
        "outputId": "38b55f7b-0314-428c-b14b-6c6940c8ab95"
      },
      "source": [
        "Mname='FSMHR00'\n",
        "\n",
        "grufn=lay.GRU\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "basefolder=\"drive/My Drive/FHRMA-Training-FS/\"\n",
        "logfolder=\"logs/\" # Tensorboard logs are saved only locally (change to drive if you want to save them)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRbdre5kSkT4"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tQSb2lIUe3_"
      },
      "source": [
        "with open(basefolder+'dataV8MHR13-13.pkl','rb') as f:\n",
        "    X_train, Y_train, X_val, Y_val, ListRec,LengthRec = pickle.load(f)\n",
        "\n",
        "samp=X_train.shape[1]\n",
        "batch_size=X_val.shape[0]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPRgCsl1Uy6e"
      },
      "source": [
        "@tf.function \n",
        "def weighted_binary_crossentropy(yTrue, yPred): \n",
        "    Pred=yPred[:,:,0]\n",
        "    Pred=tf.clip_by_value(Pred,tf.constant(.00001),tf.constant(.999999))\n",
        "    isFalse=yTrue[:,:,3]\n",
        "    docare=yTrue[:,:,2]    \n",
        "    N=(tf.keras.backend.log(Pred)*isFalse+tf.keras.backend.log(tf.constant(1.)-Pred)*(tf.constant(1.)-isFalse))*docare\n",
        "    return -tf.keras.backend.sum(N)#/tf.keras.backend.sum(docare)\n",
        "\n",
        "@tf.function \n",
        "def weighted_accuracy(yTrue, yPred):\n",
        "    \n",
        "    Pred=yPred[:,:,0]\n",
        "    isFalse=yTrue[:,:,3]\n",
        "    docare=yTrue[:,:,2] \n",
        "    C=tf.cast((Pred>tf.constant(.5)),tf.float32)    \n",
        "    N=tf.keras.backend.sum( tf.cast((C==isFalse),tf.float32) * docare)\n",
        "    return tf.keras.backend.sum(N)#/tf.keras.backend.sum(docare)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHvoa7AhVSLd"
      },
      "source": [
        "class Split(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Split, self).__init__()      \n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.split(inputs,num_or_size_splits=2, axis=0)\n",
        "\n",
        "class RevT(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(RevT, self).__init__()      \n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.keras.backend.reverse(inputs,1)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NCzQcPuZRu_"
      },
      "source": [
        "L=(os.path.getsize(basefolder+\"DiffMF.dat\")//2)\n",
        "i16=array.array(\"h\")\n",
        "with open(basefolder+'DiffMF.dat', 'rb') as f:  \n",
        "    i16.fromfile(f,L)\n",
        "DiffFM=np.asarray(i16.tolist()).reshape(-1,1)/4/60\n",
        "DiffFM=np.concatenate((DiffFM,np.flip(DiffFM,0)),0)\n",
        "DiffFM=tf.constant(DiffFM[0:samp,:],dtype=tf.float32)\n",
        "def siglossgenerator(X,Y):\n",
        "    pMHRn=np.array([4,12,24,36,64,120])*2\n",
        "    pMHRp=np.array([.35,.35,.35,.35,.35,.35])\n",
        "    pMHRd=np.array([3000,1000,300,60,20,6])\n",
        "    pFHRn=np.array([4,12,24,36,64,120])*2\n",
        "    pFHRp=np.array([.25,.25,.25,.25,.25,.25])\n",
        "    pFHRd=np.array([2000,500,150,60,20,6])\n",
        "    \n",
        "    \n",
        "\n",
        "    pKeepMHR=.15\n",
        "    pKeepFHR=.20\n",
        "    pCut=.4\n",
        "    pNoStage2=.1\n",
        "\n",
        "    pMHR0=tf.constant(.1,dtype=tf.float32)\n",
        "    stdMult=tf.constant(.08,dtype=tf.float32)\n",
        "\n",
        "   \n",
        "    rg=tf.reshape(tf.range(0,samp,dtype=tf.int32),[samp,1])\n",
        "    if tf.random.uniform([])<pCut:\n",
        "        pos=tf.random.uniform([],maxval=samp-1,dtype=tf.int32)\n",
        "        newX=tf.tensor_scatter_nd_update(X, [[pos,0],[pos,1],[pos,2],[pos,3],[pos,4],[pos,5]], [0,0,0,0,0,1])\n",
        "        newY=tf.tensor_scatter_nd_update(Y, [[pos,0],[pos,1],[pos,2],[pos,3]], [0,0,0,0])\n",
        "    else:\n",
        "        newX=X\n",
        "        newY=Y  \n",
        "\n",
        "    FHR=newX[:,0:1]\n",
        "    maskFHR=newX[:,1:2]\n",
        "    MHR=newX[:,2:3]\n",
        "    maskMHR=newX[:,3:4]\n",
        "    isStage2=newX[:,4:5]\n",
        "    care=newY[:,0:1]\n",
        "    falsesig=newY[:,1:2]\n",
        "    careM=newY[:,2:3]\n",
        "    falsesigM=newY[:,3:4]\n",
        "    \n",
        "    if tf.random.uniform([])<pNoStage2:\n",
        "        isStage2=tf.zeros(tf.shape(isStage2),dtype=tf.dtypes.float32)\n",
        "            \n",
        "  \n",
        "    if tf.random.uniform([])>pKeepMHR:\n",
        "        for k in range(len(pMHRn)):\n",
        "            N=tf.cast(tf.floor(tf.math.abs(tf.random.normal([],0,pMHRn[k],dtype=tf.float32))),tf.int32)\n",
        "            for j in range(N):\n",
        "                if tf.random.uniform([])<pMHRp[k]: # removing maternal heart rate\n",
        "                    mid=tf.random.uniform([],maxval=samp,dtype=tf.int32)\n",
        "                    dur=tf.cast(abs(tf.random.normal([],mean=pMHRd[k],stddev=pMHRd[k]/2)),tf.int32)\n",
        "                    maskMHR=tf.where( (rg<mid-dur)|(rg>=mid+dur), maskMHR, [0])  \n",
        "                    careM=tf.where( (rg<mid-dur)|(rg>=mid+dur), careM, [0])    \n",
        "        \n",
        "        N=tf.cast(tf.floor(tf.math.abs(tf.random.normal([],0,50,dtype=tf.float32))),tf.int32)\n",
        "        for j in range(N):\n",
        "            mid=tf.random.uniform([],maxval=samp,dtype=tf.int32)\n",
        "            durT=tf.cast(abs(tf.random.normal([],mean=0,stddev=160/2)),tf.int32)\n",
        "            durPart=tf.cast(abs(tf.random.normal([],mean=0,stddev=80/2)),tf.int32)\n",
        "            OffsetPart=tf.cast(tf.random.normal([],mean=0,stddev=20),tf.int32)\n",
        "            endFalse=tf.clip_by_value(durPart+OffsetPart,-durT,durT);\n",
        "            startFalse=tf.clip_by_value(-durPart+OffsetPart,-durT,durT);\n",
        "\n",
        "            \n",
        "            r=tf.random.uniform([])\n",
        "            if r<.8:\n",
        "                change=tf.where( (rg>=mid+startFalse) & (rg<mid+endFalse) & (maskMHR==1.) & (MHR<0.1), [1.], [0.] )\n",
        "                MHR=(MHR+2)*(1+change)-2\n",
        "            else:\n",
        "                change=tf.where( (rg>=mid+startFalse) & (rg<mid+endFalse) & (maskMHR==1.) & (MHR>-1.3), [1.], [0.] )\n",
        "                MHR=(MHR+2)*(1-.5*change)-2\n",
        "\n",
        "            falsesigM=tf.where( (change==1) & (falsesigM==0) & (careM>0) ,[1.],falsesigM )\n",
        "            maskMHR=tf.where( (rg<mid-durT)|(rg>=mid+durT)|(change==1.), maskMHR, [0])\n",
        "            careM=tf.where( (rg<mid-durT)|(rg>=mid+durT)|(change==1.), careM*(1+change), [0]) \n",
        "\n",
        "    if tf.random.uniform([])>pKeepFHR:\n",
        "        for k in range(len(pFHRn)):\n",
        "            N=tf.cast(tf.floor(tf.math.abs(tf.random.normal([],0,pFHRn[k],dtype=tf.float32))),tf.int32)\n",
        "            for j in range(N):\n",
        "                if tf.random.uniform([])<pFHRp[k]: # removing maternal heart rate\n",
        "                    mid=tf.random.uniform([],maxval=samp,dtype=tf.int32)\n",
        "                    dur=tf.cast(abs(tf.random.normal([],mean=pFHRd[k],stddev=pFHRd[k]/2)),tf.int32)\n",
        "                    maskFHR=tf.where( (rg<mid-dur)|(rg>=mid+dur), maskFHR, [0]) \n",
        "                    care=tf.where( (rg<mid-dur)|(rg>=mid+dur), care, [0]) \n",
        "\n",
        "        N=tf.cast(tf.floor(tf.math.abs(tf.random.normal([],0,100,dtype=tf.float32))),tf.int32)\n",
        "        for j in range(N):\n",
        "            mid=tf.random.uniform([],maxval=samp,dtype=tf.int32)\n",
        "            durT=tf.cast(abs(tf.random.normal([],mean=120,stddev=120/2)),tf.int32)\n",
        "            durPart=tf.cast(abs(tf.random.normal([],mean=60,stddev=60/2)),tf.int32)\n",
        "            OffsetPart=tf.cast(tf.random.normal([],mean=0,stddev=20),tf.int32)\n",
        "            endFalse=tf.clip_by_value(durPart+OffsetPart,-durT,durT);\n",
        "            startFalse=tf.clip_by_value(-durPart+OffsetPart,-durT,durT);\n",
        "            r=tf.random.uniform([])\n",
        "            if r<.5:\n",
        "                change=tf.where( (rg>=mid+startFalse) & (rg<mid+endFalse) & (falsesig==0.)& (care>0.), [1.], [0.] )\n",
        "            else:\n",
        "                change=tf.where( (rg>=mid+startFalse) & (rg<mid+endFalse) & (falsesig==0.)& (care>0.) & (maskMHR==1.), [1.], [0.] )\n",
        "\n",
        "            falsesig=falsesig+change\n",
        "            maskFHR=tf.where( (rg<mid-durT)|(rg>=mid+durT)|(change==1.), maskFHR, [0])\n",
        "            care=tf.where( (rg<mid-durT)|(rg>=mid+durT)|(change==1.), care*(1+change), [0]) \n",
        "            if r<.3:\n",
        "                FHR=(FHR+2)*(1+change)-2\n",
        "            elif r<.5:\n",
        "                FHR=(FHR+2)*(1-.5*change)-2\n",
        "            elif r<.9:\n",
        "                FHR=(FHR+2)*(1-change)+(MHR+2+DiffFM)*change-2\n",
        "            elif r<.95:\n",
        "                FHR=(FHR+2)*(1-change)+(MHR+2+DiffFM)*2*change-2\n",
        "            else:\n",
        "                FHR=(FHR+2)*(1-change)+(MHR+2+DiffFM)*.5*change-2\n",
        "\n",
        "            if r>.5 and tf.random.uniform([])<.5:\n",
        "                durMHRLost=tf.cast(abs(tf.random.normal([],mean=0,stddev=240)),tf.int32)\n",
        "                OffsetMHRLost=tf.cast(tf.random.normal([],mean=0,stddev=120),tf.int32)\n",
        "                maskMHR=tf.where( (rg<mid+OffsetMHRLost-durMHRLost)|(rg>=mid+OffsetMHRLost+durMHRLost), maskMHR, [0])   \n",
        "                careM=tf.where( (rg<mid+OffsetMHRLost-durMHRLost)|(rg>=mid+OffsetMHRLost+durMHRLost), careM, [0])   \n",
        "\n",
        "    maskFHR=tf.where( FHR<=2.25, maskFHR, [0])   \n",
        "    if tf.random.uniform([])<pMHR0: \n",
        "        maskMHR=tf.zeros([samp,1],dtype=tf.float32)\n",
        "        careM=tf.zeros([samp,1],dtype=tf.float32)    \n",
        "    \n",
        "    S=1.+tf.random.normal([],stddev=stdMult)\n",
        "\n",
        "    newX=tf.concat([ ((FHR+2)*S-2)*maskFHR , maskFHR, ((MHR+2)*S-2)*maskMHR,maskMHR,isStage2,newX[:,5:6] ],axis=1)\n",
        "    \n",
        "    newX=tf.ensure_shape(newX,X.shape)\n",
        "    newY=tf.concat([ care,falsesig,careM,falsesigM ],axis=1)\n",
        "    return newX,newY\n",
        "\n",
        "\n",
        "traindataset=tf.data.Dataset.from_tensor_slices(    (  tf.constant(X_train,dtype=tf.float32)  ,  tf.constant(Y_train,dtype=tf.float32)  )    )\n",
        "traindataset=traindataset.shuffle(X_train.shape[0],reshuffle_each_iteration=True).repeat()\n",
        "traindataset=traindataset.map(siglossgenerator)\n",
        "traindataset=traindataset.batch(batch_size,drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "valdataset=tf.data.Dataset.from_tensor_slices((X_val,Y_val)).cache().repeat().batch(batch_size,drop_remainder=True)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZdQ1Bw6gM71"
      },
      "source": [
        "class Sparsity(tf.keras.constraints.Constraint):\n",
        "    def __init__(self, n,h):\n",
        "        self. n = n    \n",
        "        self.h=h\n",
        "        m=np.zeros([h,h])\n",
        "        for i in range(int(h/n)):\n",
        "            m[i*n:i*n+n,i*n:i*n+n]=1.\n",
        "        self.mask=tf.constant(np.concatenate([m,m,m],axis=1),dtype=tf.float32)\n",
        "        \n",
        "    def __call__(self, w):\n",
        "        w.assign(w*self.mask)\n",
        "        return w\n",
        "\n",
        "class SparsityKernel(tf.keras.constraints.Constraint):\n",
        "    def __init__(self, m,n,slices):\n",
        "        #m input size ; n state size\n",
        "        #slices\n",
        "        ma1=np.zeros([m,n],dtype=np.float32)\n",
        "        for i in range(slices.shape[0]):\n",
        "            ma1[slices[i,0]:slices[i,1],slices[i,2]:slices[i,3]]=1.\n",
        "        self.mask=tf.constant(np.concatenate([ma1,ma1,ma1],axis=1),dtype=tf.float32)\n",
        "        ma2=np.zeros([m,3*n])\n",
        "        ma2[m-1,n:2*n]=-1.e30\n",
        "        ma2[m-1,0:n]=-1.e30\n",
        "        self.maskReset=tf.constant(ma2,dtype=tf.float32)\n",
        "    def __call__(self, w):\n",
        "        w.assign(w*self.mask+self.maskReset)\n",
        "        return w\n",
        "\n",
        "class Reseter(tf.keras.constraints.Constraint):\n",
        "    def __init__(self, m,n):\n",
        "        ma=np.zeros([m,3*n])\n",
        "        ma[m-1,n:2*n]=-1.e30\n",
        "        ma[m-1,0:n]=-1.e30\n",
        "        self.mask=tf.constant(ma,dtype=tf.float32)\n",
        "        \n",
        "    def __call__(self, w):\n",
        "        w.assign(w+self.mask)\n",
        "        return w\n",
        "\n",
        "class BiasConstraintCallback(tf.keras.callbacks.Callback):\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        for GRUlayer in [\"GRU1MHR\"]:\n",
        "            W=self.model.get_layer(GRUlayer).get_weights()\n",
        "            L=int(len(W[0][-1])/3)\n",
        "            W[0][-1][2*L:3*L]=-W[2][0][2*L:3*L]#-W[2][1][2*L:3*L] #Pour CudNN a priori W[2][2*L:3*L]-W[2][5*L:6*L] Mais à vérifier ordre des 3 couches\n",
        "            self.model.get_layer(GRUlayer).set_weights(W)\n",
        "            "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe6MIZA5gYig"
      },
      "source": [
        "\n",
        "def create_model(batch_size,siglen):\n",
        "    I=lay.Input(batch_shape= (batch_size, siglen, 6), name=\"SigInput\") \n",
        "\n",
        "    RevI=RevT()(I)\n",
        "    IforwBack=lay.concatenate([I,RevI], axis=0)\n",
        "    slicesKernel0=np.array([[2,6,0,12]])\n",
        "\n",
        "    GRU1M=grufn(12,return_sequences=True,recurrent_initializer='glorot_uniform'\n",
        "        ,stateful=False,recurrent_constraint=Sparsity(4,12),kernel_constraint=SparsityKernel(6,12,slicesKernel0),name='GRU1MHR')(IforwBack)\n",
        "    GRU1M=lay.GaussianDropout(.2)(GRU1M)\n",
        "\n",
        "    Lay0Forw,Lay0Backw=Split()(GRU1M)\n",
        "    PMat=lay.Dense(1,activation='sigmoid',name=\"DensePmat\")(lay.concatenate([Lay0Forw,RevT()(Lay0Backw)], axis=2))\n",
        "\n",
        "    model = tf.keras.Model(inputs=[I], outputs=[PMat])\n",
        "\n",
        "\n",
        "    #model.summary()\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhjCGRf7jZ25"
      },
      "source": [
        "callbacks=[tf.keras.callbacks.TensorBoard(log_dir = logfolder+Mname , histogram_freq = 0)]\n",
        "callbacks.append(tf.keras.callbacks.ModelCheckpoint(filepath=basefolder+Mname+\"/best-{epoch:05d}-{val_loss:.4f}.h5\",\n",
        "                                                 save_best_only=True,\n",
        "                                                 verbose=1))\n",
        "callbacks.append(tf.keras.callbacks.ModelCheckpoint(filepath=basefolder+Mname+\"/save-{epoch:05d}.h5\",\n",
        "                                                 save_freq=200,\n",
        "                                                 verbose=1))\n",
        "def scheduler(epoch):\n",
        "    return 2.e-3 * tf.math.exp(-.005*tf.math.log(10.)*epoch)+1.e-3\n",
        "    \n",
        "callbacks.append(tf.keras.callbacks.LearningRateScheduler(scheduler))\n",
        "callbacks.append(BiasConstraintCallback())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj3Dh2eySktA"
      },
      "source": [
        "initial_epoch=0\n",
        "with strategy.scope():\n",
        "    model=create_model(int(batch_size/strategy.num_replicas_in_sync),samp)\n",
        "    #model.load_weights(basefolder+Mname+\"/save-00000.h5\")\n",
        "    model.compile(\n",
        "        optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=weighted_binary_crossentropy,\n",
        "        metrics=[weighted_accuracy])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One epoch to create logs folders for tensorboard\n",
        "model.fit(traindataset,\n",
        "    epochs=1,\n",
        "    steps_per_epoch=np.floor(X_train.shape[0]/batch_size),\n",
        "    validation_freq=1,\n",
        "    initial_epoch=initial_epoch,\n",
        "    validation_steps=1,\n",
        "    validation_data=valdataset,\n",
        "    callbacks=callbacks \n",
        ")\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/"
      ],
      "metadata": {
        "id": "uhjvYJJtA1VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AojENTErjmum"
      },
      "source": [
        "model.fit(traindataset,\n",
        "    epochs=25000,\n",
        "    steps_per_epoch=np.floor(X_train.shape[0]/batch_size),\n",
        "    validation_freq=1,\n",
        "    initial_epoch=initial_epoch+1,\n",
        "    validation_steps=1,\n",
        "    validation_data=valdataset,\n",
        "    callbacks=callbacks \n",
        ")\n",
        "#Do not worry if val_loss is bad (0.5) on 500 firsts epochs it goes down after"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If you want to load and test the trained model\n",
        "\n",
        "!wget https://github.com/utsb-fmm/FHRMA/raw/master/FS%20training%20python%20sources/FSMHR.h5\n",
        "model.load_weights(\"FSMHR.h5\")\n",
        "model.evaluate(X_val,Y_val)"
      ],
      "metadata": {
        "id": "AU4qprkAVm5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsMNbuVlRyo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}